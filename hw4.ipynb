{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import os.path\n",
    "from scipy.stats import multivariate_normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEIGHT_THRESHOLD = 0.0  # meters\n",
    "GROUND_HEIGHT_THRESHOLD = -.4  # meters\n",
    "DT = 0.1\n",
    "X_LANDMARK = 5.  # meters\n",
    "Y_LANDMARK = -5.  # meters\n",
    "EARTH_RADIUS = 6.3781E6  # meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data17, _ = load_data(\"2020_2_26__17_21_59_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2597510387811634 0.14175408587257618\n"
     ]
    }
   ],
   "source": [
    "#accleration covariance calculations\n",
    "#assuming uncorrelated Accelx, accelY\n",
    "var_accX = np.var(data17[\"AccelX\"][669:])\n",
    "var_accY = np.var(data17[\"AccelY\"][669:])\n",
    "covar_u_t = np.array([[var_accX, 0],\n",
    "                      [0, var_accY]])\n",
    "print(var_accX, var_accY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01090831,  0.        ,  0.00109083, -0.00436332,  0.        ,\n",
       "       -0.00109083,  0.00872665,  0.00436332,  0.00654498,  0.00545415,\n",
       "        0.00654498,  0.00654498,  0.00763582,  0.00654498,  0.00654498,\n",
       "        0.00654498,  0.00654498,  0.00545415,  0.00545415,  0.00545415,\n",
       "        0.00545415,  0.00545415,  0.00654498,  0.00654498,  0.00654498,\n",
       "        0.00654498,  0.00763582,  0.00763582,  0.00763582,  0.00763582,\n",
       "        0.00763582,  0.00763582,  0.00763582,  0.00763582,  0.00763582,\n",
       "        0.00763582,  0.00763582,  0.00763582])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaw_corrected = np.zeros(len(data17[\"Yaw\"][669:]))\n",
    "yaw_data = data17[\"Yaw\"][669:]\n",
    "\n",
    "for i in range(len(data17[\"Yaw\"][669:])):\n",
    "    \n",
    "    yaw_corrected[i] = wrap_to_pi(yaw_data[i]*(np.pi/180))\n",
    "\n",
    "yaw_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001698159186405823 0.0004478908815990326 8.613675903064495e-06\n"
     ]
    }
   ],
   "source": [
    "#calculating sensor covariance matrix. We assume that all measurements are independent, and that the covariance is equal\n",
    "#to the stationary variance\n",
    "#recall: measurement vector is Zx, Zy, yaw\n",
    "var_Zx = np.var(data17[\"X\"][669:])\n",
    "var_Zy = np.var(data17[\"Y\"][669:])\n",
    "var_yaw = np.var(yaw_corrected)\n",
    "covar_z = np.array([[var_Zx, 0, 0],\n",
    "                    [ 0, var_Zy, 0],\n",
    "                    [0, 0, var_yaw]])\n",
    "print(var_Zx, var_Zy, var_yaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"Load data from the csv log\n",
    "\n",
    "    Parameters:\n",
    "    filename (str)  -- the name of the csv log\n",
    "\n",
    "    Returns:\n",
    "    data (dict)     -- the logged data with data categories as keys\n",
    "                       and values list of floats\n",
    "    \"\"\"\n",
    "    is_filtered = False\n",
    "    if os.path.isfile(filename + \"_filtered.csv\"):\n",
    "        f = open(filename + \"_filtered.csv\")\n",
    "        is_filtered = True\n",
    "    else:\n",
    "        f = open(filename + \".csv\")\n",
    "\n",
    "    file_reader = csv.reader(f, delimiter=',')\n",
    "\n",
    "    # Load data into dictionary with headers as keys\n",
    "    data = {}\n",
    "    header = [\"X\", \"Y\", \"Z\", \"Time Stamp\", \"Latitude\", \"Longitude\",\n",
    "              \"Yaw\", \"Pitch\", \"Roll\", \"AccelX\", \"AccelY\", \"AccelZ\"]\n",
    "    for h in header:\n",
    "        data[h] = []\n",
    "\n",
    "    row_num = 0\n",
    "    f_log = open(\"bad_data_log.txt\", \"w\")\n",
    "    for row in file_reader:\n",
    "        for h, element in zip(header, row):\n",
    "            # If got a bad value just use the previous value\n",
    "            try:\n",
    "                data[h].append(float(element))\n",
    "            except ValueError:\n",
    "                data[h].append(data[h][-1])\n",
    "                f_log.write(str(row_num) + \"\\n\")\n",
    "\n",
    "        row_num += 1\n",
    "    f.close()\n",
    "    f_log.close()\n",
    "\n",
    "    return data, is_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wrap_to_pi(angle):\n",
    "    \"\"\"Wrap angle data in radians to [-pi, pi]\n",
    "\n",
    "    Parameters:\n",
    "    angle (float)   -- unwrapped angle\n",
    "\n",
    "    Returns:\n",
    "    angle (float)   -- wrapped angle\n",
    "    \"\"\"\n",
    "    while angle >= math.pi:\n",
    "        angle -= 2*math.pi\n",
    "\n",
    "    while angle <= -math.pi:\n",
    "        angle += 2*math.pi\n",
    "    return angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_gps_to_xy(lat_gps, lon_gps, lat_origin, lon_origin):\n",
    "    \"\"\"Convert gps coordinates to cartesian with equirectangular projection\n",
    "\n",
    "    Parameters:\n",
    "    lat_gps     (float)    -- latitude coordinate\n",
    "    lon_gps     (float)    -- longitude coordinate\n",
    "    lat_origin  (float)    -- latitude coordinate of your chosen origin\n",
    "    lon_origin  (float)    -- longitude coordinate of your chosen origin\n",
    "\n",
    "    Returns:\n",
    "    x_gps (float)          -- the converted x coordinate\n",
    "    y_gps (float)          -- the converted y coordinate\n",
    "    \"\"\"\n",
    "    x_gps = EARTH_RADIUS*(math.pi/180.)*(lon_gps - lon_origin)*math.cos((math.pi/180.)*lat_origin)\n",
    "    y_gps = EARTH_RADIUS*(math.pi/180.)*(lat_gps - lat_origin)\n",
    "\n",
    "    return x_gps, y_gps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def propogate_state(x_t_prev, u_t):\n",
    "    \"\"\"Propogate/predict the state based on chosen motion model\n",
    "\n",
    "    Parameters:\n",
    "    x_t_prev (np.array)  -- the previous state estimate\n",
    "    u_t (np.array)       -- the current control input\n",
    "\n",
    "    Returns:\n",
    "    x_bar_t (np.array)   -- the predicted state\n",
    "    \"\"\"\n",
    "    \"\"\"STUDENT CODE START\"\"\"\n",
    "    #Xt = [xg, yg, yaw, yaw_t-1, Vx, Vy, omega]'\n",
    "    angle_correction = x_t_prev[2]\n",
    "    #angle_correction = wrap_to_pi(x_t_prev[2])\n",
    "\n",
    "    A_matrix = np.array([[1, 0, 0, 0, DT, 0, 0],\n",
    "                         [0, 1, 0, 0, 0, DT, 0],\n",
    "                         [0, 0, 1, 0, 0, 0, DT],\n",
    "                         [0, 0, 1, 0, 0, 0, 0 ],\n",
    "                         [0, 0, 0, 0, 1, 0, 0 ],\n",
    "                         [0, 0, 0, 0, 0, 1, 0 ],\n",
    "                         [0, 0, 1/DT, -1/DT, 0, 0, 0]])\n",
    "    \n",
    "    #angle_correction = wrap_to_pi(2*np.pi - x_t_prev[2])\n",
    "    \n",
    "    \n",
    "    #angle_correction = wrap_to_pi(-x_t_prev[2])\n",
    "\n",
    "\n",
    "    B_matrix = np.array([[1/2*np.square(DT)*np.cos(angle_correction), 0],\n",
    "                     [-1/2*np.square(DT)*np.sin(angle_correction), 0],\n",
    "                     [0, 0],\n",
    "                     [0, 0],\n",
    "                     [DT*np.cos(angle_correction), 0], \n",
    "                     [-DT*np.sin(angle_correction), 0],\n",
    "                     [0, 0]])\n",
    "\n",
    "    x_bar_t = A_matrix@x_t_prev + B_matrix@u_t\n",
    "    x_bar_t[2] = wrap_to_pi((A_matrix@x_t_prev)[2] + (B_matrix@u_t)[2])\n",
    "    x_bar_t[3] = wrap_to_pi((A_matrix@x_t_prev)[3] + (B_matrix@u_t)[3])\n",
    "    \n",
    "    \n",
    "    x_bar_t[6] = wrap_to_pi(x_t_prev[2] - x_t_prev[3]) / DT\n",
    "    #x_bar_t[6] = (wrap_to_pi(x_t_prev[2]) - wrap_to_pi(x_t_prev[3])) / DT\n",
    "    #x_bar_t[2] = wrap_to_pi(x_bar_t[2])\n",
    "\n",
    "    \"\"\"STUDENT CODE END\"\"\"\n",
    "\n",
    "    return x_bar_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Representation\n",
    "\n",
    "### At each time step, the ith row of the particle matrix has the states corresponding to the ith particle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWeight(x_t, z_t, covar_z_t):\n",
    "    \n",
    "    estimated = x_t[0:3]\n",
    "    \n",
    "    weight = multivariate_normal.pdf(z_t, mean=estimated, cov=covar_z_t)\n",
    "    \n",
    "#     if weight == 0:\n",
    "#         print(\"getWeight\")\n",
    "#         print('x_t')\n",
    "#         print(x_t)\n",
    "#         print('estimated')\n",
    "#         print(estimated)\n",
    "#         print('z_t')\n",
    "#         print(z_t)\n",
    "#         print('weight')\n",
    "#         print(weight)\n",
    "#         print(\"wtf\")\n",
    "    \n",
    "    return weight\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_step(x_t_prev, u_t, covar_u_t, z_t, covar_z_t):\n",
    "    '''\n",
    "    z_t is the bot's position in the global frame\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    x_t_bar = np.zeros(x_t_prev.shape)\n",
    "    weights = np.zeros(len(x_t_prev))\n",
    "    \n",
    "    for i in range(len(x_t_prev)):\n",
    "        perturbed_u_t = np.zeros(2)\n",
    "        \n",
    "        # Get previous state\n",
    "        prev_state = x_t_prev[i]\n",
    "        \n",
    "        # Perturb control input\n",
    "        perturbed_u_t[0] = u_t[0] + np.random.normal(loc = 0, scale = np.sqrt(covar_u_t[0][0]))\n",
    "        perturbed_u_t[1] = u_t[1] + np.random.normal(loc = 0, scale = np.sqrt(covar_u_t[1][1]))\n",
    "        \n",
    "        # Get new state using perturbed control input\n",
    "        new_state = propogate_state(prev_state, perturbed_u_t)\n",
    "        new_weight = getWeight(new_state, z_t, covar_z_t)\n",
    "        \n",
    "        # Store\n",
    "        x_t_bar[i] = new_state\n",
    "        weights[i] = new_weight\n",
    "        \n",
    "#     if np.isnan(np.sum(weights)):\n",
    "#         print(\"hello\")\n",
    "#         print(x_t_prev)\n",
    "#         print(z_t)\n",
    "#         print(weights)\n",
    "#         print('hiiii')\n",
    "    \n",
    "    weights_sum = weights/np.sum(weights)\n",
    "    \n",
    "#     if np.isnan(np.sum(weights_sum)):\n",
    "#         print(x_t_prev)\n",
    "#         print(z_t)\n",
    "#         print(weights)\n",
    "#         print(np.sum(weights))\n",
    "    #print(np.sum(weights))\n",
    "        \n",
    "    return x_t_bar, weights_sum\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction_step(x_bar_t, weights):\n",
    "    \n",
    "    x_t = np.zeros(x_bar_t.shape)\n",
    "    #weights = np.zeros(len(x_bar_t))\n",
    "        \n",
    "    x_ind = np.arange(len(x_bar_t))\n",
    "    \n",
    "    for i in range(len(x_bar_t)):\n",
    "        \n",
    "        #print(x_ind.shape)\n",
    "        #print(weights.shape)\n",
    "        #print(\"correction\")\n",
    "        #print(np.sum(weights))\n",
    "        \n",
    "#         if np.isnan(np.sum(weights)):\n",
    "#             print(weights)\n",
    "        x_t_index = np.random.choice(a = x_ind, p = weights)\n",
    "        \n",
    "        x_t[i] = x_bar_t[x_t_index]\n",
    "        #weights[i] = weights[x_t_index]\n",
    "        \n",
    "    return x_t\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initializeParticles(numParticles, numStates):\n",
    "    \n",
    "    states = np.zeros([numParticles, numStates])\n",
    "    \n",
    "    x_col = np.random.normal(loc = 0, scale = 0.1, size = numParticles)\n",
    "    y_col = np.random.normal(loc = 0, scale = 0.1, size = numParticles)\n",
    "    \n",
    "    yaw_col = np.random.normal(loc = 0, scale = 0.01, size = numParticles)\n",
    "    #yaw_col = np.where(yaw_col < 0, yaw_col + np.pi*2, yaw_col)\n",
    "    \n",
    "    states[:, 0] = x_col\n",
    "    states[:, 1] = y_col\n",
    "    states[:, 2] = yaw_col\n",
    "    states[:, 3] = yaw_col\n",
    "        \n",
    "    return states\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    filename = '2020_2_26__17_21_59_filtered'\n",
    "    data, is_filtered = load_data(filename)\n",
    "    \n",
    "    # Load data into variables\n",
    "    x_lidar = data[\"X\"]\n",
    "    y_lidar = data[\"Y\"]\n",
    "    z_lidar = data[\"Z\"]\n",
    "    time_stamps = data[\"Time Stamp\"]\n",
    "    lat_gps = data[\"Latitude\"]\n",
    "    lon_gps = data[\"Longitude\"]\n",
    "    yaw_lidar = data[\"Yaw\"]\n",
    "    pitch_lidar = data[\"Pitch\"]\n",
    "    roll_lidar = data[\"Roll\"]\n",
    "    x_ddot = data[\"AccelX\"]\n",
    "    y_ddot = data[\"AccelY\"]\n",
    "    \n",
    "    lat_origin = lat_gps[0]\n",
    "    lon_origin = lon_gps[0]\n",
    "    \n",
    "    # Initialize filter\n",
    "    numParticles = 1000\n",
    "    numStates = 7\n",
    "    x_t_prev = initializeParticles(numParticles, numStates)\n",
    "    \n",
    "    # Store particles and gps\n",
    "    particles = np.empty((numParticles, numStates, len(time_stamps)))\n",
    "    gps_estimates = np.empty((2, len(time_stamps)))\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    for t, _ in enumerate(time_stamps):\n",
    "        #print('Index')\n",
    "        #print(index)\n",
    "        index = index + 1\n",
    "        \n",
    "        u_t = np.array([x_ddot[t], y_ddot[t]])\n",
    "        \n",
    "        converted_yaw = wrap_to_pi(yaw_lidar[t] * np.pi / 180)\n",
    "        \n",
    "        z_t = np.array([5 - (x_lidar[t]*(-np.sin(converted_yaw)) + y_lidar[t]*(np.cos(converted_yaw))),\n",
    "                        -5 - (x_lidar[t]*(-np.cos(converted_yaw)) - y_lidar[t]*(np.sin(converted_yaw))),\n",
    "                        converted_yaw])\n",
    "        \n",
    "        # Prediction Step\n",
    "        x_bar_t, weights = prediction_step(x_t_prev, u_t, covar_u_t, z_t, covar_z)\n",
    "        #print(np.sum(weights))\n",
    "        \n",
    "        # Correction Step\n",
    "        x_t = correction_step(x_bar_t, weights)\n",
    "        \n",
    "        \n",
    "        # Explicitly set x_prev_t to x_t\n",
    "        x_prev_t = x_t\n",
    "        \n",
    "        # Store shit\n",
    "        particles[:, :, t] = x_t\n",
    "\n",
    "        x_gps, y_gps = convert_gps_to_xy(lat_gps=lat_gps[t],\n",
    "                                         lon_gps=lon_gps[t],\n",
    "                                         lat_origin=lat_origin,\n",
    "                                         lon_origin=lon_origin)\n",
    "        gps_estimates[:, t] = np.array([x_gps, y_gps])\n",
    "        \n",
    "    return particles, gps_estimates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christinalau/anaconda/envs/E190/lib/python3.7/site-packages/ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-95faae6e5265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparticles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgps_estimates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-151-c29a0b45e733>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Correction Step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrection_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_bar_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-149-0e2a9152da00>\u001b[0m in \u001b[0;36mcorrection_step\u001b[0;34m(x_bar_t, weights)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#         if np.isnan(np.sum(weights)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#             print(weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx_t_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_bar_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_t_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "particles, gps_estimates = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = np.ones(1000)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "789"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(a = np.arange(1000), p = test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e190",
   "language": "python",
   "name": "e190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
